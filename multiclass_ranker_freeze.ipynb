{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"multiclass_ranker_freeze.ipynb","provenance":[{"file_id":"13yTqUaVs39Mqqmw0g3FL-2Bg4hiznuCG","timestamp":1630352165080}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WXAVj_jDPqSa","executionInfo":{"status":"ok","timestamp":1630457063280,"user_tz":-60,"elapsed":16528,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"ff964719-1e4b-4dad-ab9f-2cee0fd71d34"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-XZXriOmRGF1","executionInfo":{"status":"ok","timestamp":1630457063281,"user_tz":-60,"elapsed":38,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"7444d101-7caa-4d12-f22a-b5134ad2b9ea"},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Sep  1 00:44:22 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"VO_cHETDQHR0","executionInfo":{"status":"ok","timestamp":1630457070819,"user_tz":-60,"elapsed":7544,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}}},"source":["import os\n","import pickle\n","import random\n","from collections import Counter\n","import time\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from matplotlib import pyplot as plt\n","\n","## pytorch libraries\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, random_split\n","from torch.nn.utils.rnn import pad_sequence\n","\n","\n","import torchtext\n","from torchtext import data\n","from torchtext.datasets import YahooAnswers\n","from torchtext.data import get_tokenizer\n","\n","from torchtext.vocab import vocab, GloVe\n","\n","\n","import spacy"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"htRy_l6j9uyw"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"uuGugFgbQSWq","executionInfo":{"status":"ok","timestamp":1630457070833,"user_tz":-60,"elapsed":27,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"1b92733d-9c2a-4130-9794-ebcb853fac53"},"source":["os.getcwd()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content'"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"5TFyqUQet9m6"},"source":["# Load data"]},{"cell_type":"code","metadata":{"id":"4VpuKUNTQaOr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630457092025,"user_tz":-60,"elapsed":21209,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"f4407253-8ef5-4857-b462-751ef87063d8"},"source":["# set up training and test set iterators \n","\n","train_iter, test_iter = YahooAnswers(split = ('train', 'test'))"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["yahoo_answers_csv.tar.gz: 319MB [00:03, 91.6MB/s]\n"]}]},{"cell_type":"code","metadata":{"id":"YiFLuCRuv9DH","executionInfo":{"status":"ok","timestamp":1630457107536,"user_tz":-60,"elapsed":15543,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}}},"source":["## convert training and test data to map-style datasets (lists) - easier to work with\n","\n","train_data = list(train_iter)\n","test_data = list(test_iter)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"QMYBGM23wCPt","executionInfo":{"status":"ok","timestamp":1630457108260,"user_tz":-60,"elapsed":731,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}}},"source":["## original train dataset is very large: \n","len(train_data)\n","\n","# for prototyping purposes, we will only use 5% of this data\n","train_keep, train_discard = train_test_split(list(train_data), train_size = 0.05, \n","                                        random_state = 123)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZrR2WQONPl-r","executionInfo":{"status":"ok","timestamp":1630457108262,"user_tz":-60,"elapsed":25,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}}},"source":["# further divide the training set into train and validation set\n","# 70% train, 30% validation\n","\n","train_data, val_data = train_test_split(list(train_keep), train_size = 0.7, \n","                                        random_state = 123)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ESTCvaLFSUtI"},"source":["Review data splits"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Jxd40NhSPyM","executionInfo":{"status":"ok","timestamp":1630457108263,"user_tz":-60,"elapsed":25,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"dacbe72f-4290-40ed-bac3-e2499cb08173"},"source":["print(f'Train instances: {len(train_data)}')\n","print(f'Val instances: {len(val_data)}')\n","print(f'Test instances: {len(test_data)}')"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Train instances: 49000\n","Val instances: 21000\n","Test instances: 60000\n"]}]},{"cell_type":"markdown","metadata":{"id":"5LyPs7e_AyCm"},"source":["# Build data processing pipeline"]},{"cell_type":"markdown","metadata":{"id":"w_PChIg20pfM"},"source":["Beginning of Pytorch pipeline. The following neural network architecture is based on https://github.com/bentrevett/pytorch-sentiment-analysis"]},{"cell_type":"markdown","metadata":{"id":"V_4dKIWaz88u"},"source":["Set up tokeniser - in this case, will use Spacy and large language model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Vduxxvy7DJ7","executionInfo":{"status":"ok","timestamp":1630457284601,"user_tz":-60,"elapsed":176345,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"2cea5cff-4158-4772-f96a-01cff5540e4e"},"source":["# download Spacy large English language model into google colab environment\n","\n","!python -m spacy download en_core_web_lg"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting en_core_web_lg==2.2.5\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9 MB)\n","\u001b[K     |████████████████████████████████| 827.9 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.5)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.19.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (57.4.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.2)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.5)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.62.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.6.4)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.5.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2021.5.30)\n","Building wheels for collected packages: en-core-web-lg\n","  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-py3-none-any.whl size=829180942 sha256=40fa47685432a370ec009718ccaf152747d17a957dc88b4ad082c41a4120b176\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-s3sd27fy/wheels/11/95/ba/2c36cc368c0bd339b44a791c2c1881a1fb714b78c29a4cb8f5\n","Successfully built en-core-web-lg\n","Installing collected packages: en-core-web-lg\n","Successfully installed en-core-web-lg-2.2.5\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_lg')\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SQZsaf3T-pVo","executionInfo":{"status":"ok","timestamp":1630457286126,"user_tz":-60,"elapsed":1537,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"d3db017e-18ff-4c21-e009-a81e70935ca1"},"source":["#Link alias 'en' to large language english model\n","\n","!python -m spacy link en_core_web_lg en --force"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/en_core_web_lg -->\n","/usr/local/lib/python3.7/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"jiMDPB5L_0C8","executionInfo":{"status":"ok","timestamp":1630457296798,"user_tz":-60,"elapsed":10676,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"718f0fa4-af39-47a5-e193-419ce58149bb"},"source":["#checking to ensure the linkage works\n","\n","\n","nlp = spacy.load('en')\n","nlp.meta['name']"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'core_web_lg'"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"IbSyPOGA6G4o","executionInfo":{"status":"ok","timestamp":1630457307070,"user_tz":-60,"elapsed":10277,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}}},"source":["# use spacy tokenizer\n","tokenizer = get_tokenizer('spacy', language = 'en')"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8EHpoSDUqrWz","executionInfo":{"status":"ok","timestamp":1630457307072,"user_tz":-60,"elapsed":38,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"53f62309-d46a-4fb3-e9a7-0c629d2980d0"},"source":["## set up pytorch device\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","metadata":{"id":"7Sqzj8QIEUK3","executionInfo":{"status":"ok","timestamp":1630457335538,"user_tz":-60,"elapsed":28256,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}}},"source":["# build vocabulary of corpus\n","\n","\n","#tokenize all questions in train dataset\n","counter = Counter()\n","\n","for (label, line) in train_data:\n","  counter.update(tokenizer(line))"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"pfU7netyFCuR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630457335546,"user_tz":-60,"elapsed":39,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"ba7ca1f3-7bf2-485d-a8fb-90d2e87c95dd"},"source":["# add minimum frequency required to be considered in vocabulary\n","# Lets say minimum of 20 occurences to be considered in the vocabulary\n","\n","clean_counter = {token: counter[token] for token in counter if counter[token] >= 20}\n","min(clean_counter.values())"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["20"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"vyn1tqQN4K0p","executionInfo":{"status":"ok","timestamp":1630457335966,"user_tz":-60,"elapsed":436,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}}},"source":["#construct vocabulary\n","vocabulary = vocab(clean_counter, min_freq = 10) #fairly large corpus, only include words which appear at least 10 times"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"DUZjxQYPJvPX","executionInfo":{"status":"ok","timestamp":1630457335967,"user_tz":-60,"elapsed":147,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}}},"source":["# add <unk> token for out of vocab words and corresponding default index\n","\n","unk_token = '<unk>'\n","\n","vocabulary.insert_token(unk_token, 0)\n","vocabulary.set_default_index(vocabulary[unk_token])"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q8wju3j9-qPD","executionInfo":{"status":"ok","timestamp":1630457335967,"user_tz":-60,"elapsed":145,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"e9a7c51a-970e-4761-a2b1-58b0b7a4c4bf"},"source":["# get size of our vocabulary\n","\n","len(vocabulary)"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11748"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"EHn-KZ98urY_"},"source":["## Set up batching"]},{"cell_type":"markdown","metadata":{"id":"TBa9EVag2jlR"},"source":["Set up batching iterator"]},{"cell_type":"markdown","metadata":{"id":"Mxj8ZVXDcz26"},"source":["Custom functions in this section are adapted from https://colab.research.google.com/github/pytorch/text/blob/master/examples/legacy_tutorial/migration_tutorial.ipynb"]},{"cell_type":"code","metadata":{"id":"d0nvEnJzcs0z","executionInfo":{"status":"ok","timestamp":1630457335968,"user_tz":-60,"elapsed":117,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}}},"source":["# define a custom lambda function:\n","# adds special symbols to mark the start and end of a sentence\n","\n","# text_transform = lambda x: [vocabulary['<BOS>']] + [vocabulary[token] for token in tokenizer(x)] + [vocabulary['<EOS>']]\n","\n","text_transform = lambda x: [vocabulary[token] for token in tokenizer(x)]"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ik4s83RwFt9X"},"source":["define a custom function for batching: in a given batch, dynamically add padding to match the longest sentence present ."]},{"cell_type":"code","metadata":{"id":"0FCD_d9NnKB6","executionInfo":{"status":"ok","timestamp":1630457335968,"user_tz":-60,"elapsed":114,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}}},"source":["#add <pad> token to vocabulary at specified index\n","\n","pad_token = '<pad>'\n","\n","vocabulary.append_token(pad_token)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"LdeK35BgwGEg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630457335969,"user_tz":-60,"elapsed":114,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"d8f3b308-59c5-4d4f-ce6c-08d839419251"},"source":["vocabulary.__getitem__(pad_token)"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11748"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"yjnJ6qNA85fE","executionInfo":{"status":"ok","timestamp":1630457335969,"user_tz":-60,"elapsed":77,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}}},"source":["def collate_batch(batch):\n","  label_list, text_list = [], []\n","\n","  for (label, text) in batch:\n","    label_list.append(label-1) #original data is labelled 1-10; this rescales to 0-9\n","    processed_text = torch.tensor(text_transform(text))\n","    text_list.append(processed_text)\n","\n","  label_out = torch.tensor(label_list)\n","\n","  #label_out =  nn.functional.one_hot(label_tensor, 10) #one hot encode target variable\n","  #label_out = label_out.type(torch.float)\n","\n","  text_out = pad_sequence(text_list, padding_value= vocabulary.__getitem__(pad_token))\n","\n","  return label_out.to(device), text_out.to(device)\n","  \n","\n","\n"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"S7_AGIbUfuSU","executionInfo":{"status":"ok","timestamp":1630457335970,"user_tz":-60,"elapsed":78,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}}},"source":["# Using results from Yin et al, using 200 batches seems optimal. \n","# We run initial experiments using this value\n","# batch_size = int(np.ceil(len(train_data) / 200))\n","# print(batch_size)\n","\n","# ^ batch sizes above used up too much memory. Lets default to using the \n","# batch size = 40 used in the paper\n","\n","batch_size = 40\n","\n","# load training, validation and test data into pytorch pipeline.\n","# batching and preprocessing is done using these custom functions\n","\n","train_bloader = DataLoader(train_data, batch_size = batch_size,\n","                           collate_fn = collate_batch)\n","\n","val_bloader = DataLoader(val_data, batch_size = batch_size,\n","                         collate_fn = collate_batch)\n","\n","test_bloader = DataLoader(test_data, batch_size = batch_size,\n","                          collate_fn = collate_batch)"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mDUmvMD-3AUE"},"source":["# Build the model"]},{"cell_type":"markdown","metadata":{"id":"5OLmz3y63Fgi"},"source":["Model follows LSTM architecture from https://github.com/bentrevett/pytorch-sentiment-analysis. \n","Specifically \"2 - Upgraded Sentiment Analysis\"\n","\n","Edits to this architecture were made so it may be used in multi-class classification, as described in \"5 - Multi - Class Sentiment Analysis\""]},{"cell_type":"code","metadata":{"id":"buaTBpXu259H","executionInfo":{"status":"ok","timestamp":1630457335970,"user_tz":-60,"elapsed":77,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}}},"source":["class RNN(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_size, output_dim, n_layers, \n","                 bidirectional, dropout, pad_idx, pretrained_embed):\n","        \n","        super().__init__()\n","        \n","        # use pretrained embeddings and FREEZE WEIGHTS\n","        self.embedding = nn.Embedding.from_pretrained(pretrained_embed, \n","                                                      freeze = True,\n","                                                      padding_idx = pad_idx)\n","        \n","        #bidirectional rnn:processing words in  a sentence both forward and backward\n","        self.rnn = nn.LSTM(embedding_dim, \n","                           hidden_size, \n","                           num_layers=n_layers, \n","                           bidirectional=bidirectional, \n","                           dropout=dropout)\n","        \n","        # final linear layer takes hidden state from both a forward and backwards pass\n","        self.fc = nn.Linear(hidden_size * 2, output_dim) #as many output layers as there are classes\n","        \n","        #probability of dropping each neuron\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, text):\n","        \n","        #text = [sent len, batch size]\n","        \n","        embedded = self.dropout(self.embedding(text))\n","        \n","        #embedded = [sent len, batch size, emb dim]\n","        \n","        #pack sequence\n","        # lengths need to be on CPU!\n","\n","  \n","        \n","        output, (hidden, cell) = self.rnn(embedded)           \n","\n","        #output = [sent len, batch size, hid dim * num directions]\n","       \n","        \n","       \n","        #cell = [num layers * num directions, batch size, hid dim]\n","\n","\n","        #lstm outputs a tensor witth dimensions:\n","        #hidden = [num layers * num directions, batch size, hid dim]\n","        # alternatively: [forward_layer_0, backward_layer_0, forward_layer_1, \n","        #                 backward_layer_1.....,forward_layer_n, backward_layer_n]\n","\n","        #we want the final FORWARD hidden state and the last BACKWARD hidden state\n","        \n","        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n","        #and apply dropout\n","\n","        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n","                \n","        #hidden = [batch size, hid dim * 2]\n","\n","        return self.fc(hidden)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"POl1exu96T-c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630457549255,"user_tz":-60,"elapsed":213361,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"df105199-f60d-4edd-df10-d1241e012f83"},"source":["# get pretrained word embeddings for vocabulary\n","\n","vec = GloVe(name = '6B', dim = 100)\n","embed = vec.get_vecs_by_tokens(vocabulary.get_itos())\n","embed"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":[".vector_cache/glove.6B.zip: 862MB [02:40, 5.37MB/s]                           \n","100%|█████████▉| 399999/400000 [00:22<00:00, 17545.95it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [-0.0465,  0.6197,  0.5665,  ..., -0.3762, -0.0325,  0.8062],\n","        [ 0.2949,  0.5687, -0.2025,  ..., -0.1688,  0.5189, -0.5009],\n","        ...,\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"uD1DG2h_rMOI","executionInfo":{"status":"ok","timestamp":1630457549256,"user_tz":-60,"elapsed":44,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}}},"source":["# input model hyperparameters\n","\n","input_dim = len(vocabulary)\n","embedding_dim = 100\n","hidden_size = 20 # from Yin et.al\n","output_dim = 10 #data contains 10 possible classes\n","n_layers = 2\n","dropout = 0.25\n","pad_idx = vocabulary.__getitem__('<pad>')\n","bidirectional = True\n","\n","#specify pretrained embeddings\n","pretrained_embed = embed\n","\n","model = RNN(input_dim, embedding_dim, hidden_size, output_dim,\n","            n_layers, bidirectional, dropout, pad_idx, pretrained_embed)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y63-d1nYnidP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630457549257,"user_tz":-60,"elapsed":44,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"47a919d1-583c-4f6f-d1b7-5e591b4c49af"},"source":["# check to see pretrained embeddings have been correctly initialised\n","\n","model.embedding.weight.data[0:5]"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [-4.6539e-02,  6.1966e-01,  5.6647e-01, -4.6584e-01, -1.1890e+00,\n","          4.4599e-01,  6.6035e-02,  3.1910e-01,  1.4679e-01, -2.2119e-01,\n","          7.9239e-01,  2.9905e-01,  1.6073e-01,  2.5324e-02,  1.8678e-01,\n","         -3.1001e-01, -2.8108e-01,  6.0515e-01, -1.0654e+00,  5.2476e-01,\n","          6.4152e-02,  1.0358e+00, -4.0779e-01, -3.8011e-01,  3.0801e-01,\n","          5.9964e-01, -2.6991e-01, -7.6035e-01,  9.4222e-01, -4.6919e-01,\n","         -1.8278e-01,  9.0652e-01,  7.9671e-01,  2.4825e-01,  2.5713e-01,\n","          6.2320e-01, -4.4768e-01,  6.5357e-01,  7.6902e-01, -5.1229e-01,\n","         -4.4333e-01, -2.1867e-01,  3.8370e-01, -1.1483e+00, -9.4398e-01,\n","         -1.5062e-01,  3.0012e-01, -5.7806e-01,  2.0175e-01, -1.6591e+00,\n","         -7.9195e-02,  2.6423e-02,  2.2051e-01,  9.9714e-01, -5.7539e-01,\n","         -2.7266e+00,  3.1448e-01,  7.0522e-01,  1.4381e+00,  9.9126e-01,\n","          1.3976e-01,  1.3474e+00, -1.1753e+00,  3.9503e-03,  1.0298e+00,\n","          6.4637e-02,  9.0887e-01,  8.2872e-01, -4.7003e-01, -1.0575e-01,\n","          5.9160e-01, -4.2210e-01,  5.7331e-01, -5.4114e-01,  1.0768e-01,\n","          3.9784e-01, -4.8744e-02,  6.4596e-02, -6.1437e-01, -2.8600e-01,\n","          5.0670e-01, -4.9758e-01, -8.1570e-01,  1.6408e-01, -1.9630e+00,\n","         -2.6693e-01, -3.7593e-01, -9.5847e-01, -8.5840e-01, -7.1577e-01,\n","         -3.2343e-01, -4.3121e-01,  4.1392e-01,  2.8374e-01, -7.0931e-01,\n","          1.5003e-01, -2.1540e-01, -3.7616e-01, -3.2502e-02,  8.0620e-01],\n","        [ 2.9492e-01,  5.6874e-01, -2.0245e-01,  5.0244e-01, -6.8298e-01,\n","         -2.5191e-01,  4.1217e-01,  5.1773e-01, -8.8024e-01,  6.3567e-01,\n","          2.1309e+00, -2.4511e-01, -7.5815e-02, -2.5762e-03, -3.1433e-01,\n","         -2.4010e-01, -5.5284e-01,  4.5192e-01, -6.9756e-01, -3.3214e-01,\n","          6.5896e-01,  6.7103e-01,  4.5238e-01,  7.3866e-01,  8.6537e-01,\n","          6.1505e-01,  6.4161e-01, -1.8787e-01,  2.8622e-01, -5.2598e-01,\n","         -1.3051e-01,  5.9725e-01,  2.7587e-01,  3.0522e-01,  5.2697e-01,\n","         -4.6459e-02,  8.3338e-02,  8.3913e-01, -1.6261e-01,  1.0265e+00,\n","          6.0162e-01, -6.3810e-01, -5.1110e-02, -4.6125e-01,  1.6274e-01,\n","          1.5509e-01,  1.4921e-01,  2.5309e-02, -5.1424e-02,  3.9739e-01,\n","          1.1853e-01, -6.3928e-01,  1.3937e+00,  4.9129e-01, -4.4573e-01,\n","         -1.8268e+00, -2.4739e-01,  3.2170e-01,  1.4426e+00, -3.5258e-01,\n","         -2.2286e-01, -7.3146e-02, -1.2323e-01,  4.1563e-02,  1.1463e+00,\n","          4.7331e-01,  6.0112e-01,  3.4345e-01,  1.4574e+00, -7.6679e-02,\n","         -7.6200e-02,  1.8432e-01, -1.2588e-01, -5.5710e-02,  5.8187e-01,\n","         -4.0196e-01,  2.1823e-01,  2.5460e-01,  2.3451e-01, -3.8204e-01,\n","          1.8717e-01, -7.9893e-01, -4.5773e-01, -8.0082e-01,  2.7877e-01,\n","          2.0776e-01,  4.8003e-01, -1.0028e+00,  1.2646e+00,  3.8642e-01,\n","         -1.0749e-01,  8.7334e-01,  5.6184e-02,  7.8343e-01,  9.8624e-02,\n","         -2.6112e-01, -1.2315e+00, -1.6875e-01,  5.1895e-01, -5.0086e-01],\n","        [ 1.1461e+00,  5.9437e-01, -5.3163e-01, -4.5519e-01, -6.2977e-02,\n","          1.0753e+00, -5.3406e-01, -5.1192e-01,  3.6142e-01, -2.5835e-01,\n","         -1.0634e+00, -8.6520e-01,  2.5168e-02, -2.6638e-01,  2.5958e-01,\n","         -2.1335e-01,  2.0005e-01,  5.1830e-01, -4.3217e-01,  2.1032e-01,\n","          1.3694e+00, -1.7779e-01, -1.8105e-01,  3.5020e-01,  2.5166e-01,\n","          1.3172e-01,  8.1949e-02, -1.1336e+00,  1.1267e-01,  6.4866e-01,\n","         -1.2986e-01,  6.3095e-01,  1.0793e+00,  3.3409e-01,  7.2084e-01,\n","         -3.0353e-01, -7.7239e-02,  4.9292e-01, -4.2260e-01,  9.0086e-01,\n","         -7.3391e-01,  1.9088e-01,  3.2638e-02, -1.1076e-01, -3.8532e-01,\n","         -4.6533e-01, -4.6476e-01, -1.2417e-02,  7.2714e-02, -1.6606e-01,\n","          2.3019e-01, -1.7140e-01, -7.0365e-01,  4.0645e-02, -8.5640e-01,\n","         -1.7267e+00,  4.4091e-01,  2.6099e-01,  1.5430e+00, -1.0171e-01,\n","         -2.3440e-01,  2.7042e-01,  9.0621e-01, -8.6555e-01,  7.8547e-01,\n","          6.0428e-01,  8.3582e-01,  3.8548e-01,  1.3008e-01, -4.4339e-02,\n","          1.7975e-01, -4.1581e-01, -3.6926e-01,  2.2443e-01, -3.7727e-01,\n","         -6.1703e-01,  4.1241e-01, -5.9823e-01, -6.1209e-01, -5.0579e-01,\n","         -9.2796e-01, -8.4656e-01,  1.5245e+00,  3.3795e-01, -1.3485e+00,\n","         -9.3731e-01, -2.4741e-01,  2.5490e-01,  3.5762e-01, -7.3748e-01,\n","         -8.0530e-02, -6.5776e-01,  2.6258e-01,  8.5964e-02, -5.1079e-03,\n","          1.1292e-01, -6.5994e-01,  3.3636e-01,  9.1743e-02,  2.6152e-01],\n","        [-7.1953e-02,  2.3127e-01,  2.3731e-02, -5.0638e-01,  3.3923e-01,\n","          1.9590e-01, -3.2943e-01,  1.8364e-01, -1.8057e-01,  2.8963e-01,\n","          2.0448e-01, -5.4960e-01,  2.7399e-01,  5.8327e-01,  2.0468e-01,\n","         -4.9228e-01,  1.9974e-01, -7.0237e-02, -8.8049e-01,  2.9485e-01,\n","          1.4071e-01, -1.0090e-01,  9.9449e-01,  3.6973e-01,  4.4554e-01,\n","          2.8998e-01, -1.3760e-01, -5.6365e-01, -2.9365e-02, -4.1220e-01,\n","         -2.5269e-01,  6.3181e-01, -4.4767e-01,  2.4363e-01, -1.0813e-01,\n","          2.5164e-01,  4.6967e-01,  3.7550e-01, -2.3613e-01, -1.4129e-01,\n","         -4.4537e-01, -6.5737e-01, -4.2421e-02, -2.8636e-01, -2.8811e-01,\n","          6.3766e-02,  2.0281e-01, -5.3542e-01,  4.1307e-01, -5.9722e-01,\n","         -3.8614e-01,  1.9389e-01, -1.7809e-01,  1.6618e+00, -1.1819e-02,\n","         -2.3737e+00,  5.8427e-02, -2.6980e-01,  1.2823e+00,  8.1925e-01,\n","         -2.2322e-01,  7.2932e-01, -5.3211e-02,  4.3507e-01,  8.5011e-01,\n","         -4.2935e-01,  9.2664e-01,  3.9051e-01,  1.0585e+00, -2.4561e-01,\n","         -1.8265e-01, -5.3280e-01,  5.9518e-02, -6.6019e-01,  1.8991e-01,\n","          2.8836e-01, -2.4340e-01,  5.2784e-01, -6.5762e-01, -1.4081e-01,\n","          1.0491e+00,  5.1340e-01, -2.3816e-01,  6.9895e-01, -1.4813e+00,\n","         -2.4870e-01, -1.7936e-01, -5.9137e-02, -8.0560e-02, -4.8782e-01,\n","          1.4487e-02, -6.2590e-01, -3.2367e-01,  4.1862e-01, -1.0807e+00,\n","          4.6742e-01, -4.9931e-01, -7.1895e-01,  8.6894e-01,  1.9539e-01]])"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"1BD_atRb0Pbh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630457549259,"user_tz":-60,"elapsed":27,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"880fc492-2764-4659-c368-4f53a54ce241"},"source":["#check to ensure that the <pad> and <unk> tokens have been initialised as zeroes\n","print(model.embedding.weight.data[0])\n","print(model.embedding.weight.data[-1]) #pad token was stored as last embedding"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0.])\n"]}]},{"cell_type":"code","metadata":{"id":"sDUcOcnKsKhK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630457559109,"user_tz":-60,"elapsed":9859,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"b1823eee-6311-4eb7-864d-45aa8711a616"},"source":["# set up optimizer and loss function\n","\n","optimizer = optim.Adam(model.parameters())\n","criterion = nn.CrossEntropyLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)\n","\n","print(device)"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","metadata":{"id":"CDGUUGLxscQ9","executionInfo":{"status":"ok","timestamp":1630457559110,"user_tz":-60,"elapsed":72,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}}},"source":["# define accuracy function\n","\n","def categorical_accuracy(preds, y):\n","  top_pred = preds.argmax(1, keepdim = True) #for each element in the batch, what is the index with the highest output?\n","  correct = top_pred.eq(y.view_as(top_pred)).sum() #how many times did this predictions = correct label\n","  acc = correct.float() / y.shape[0] #average over entire batch\n","  return acc"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"7I_D94C2wgxH","executionInfo":{"status":"ok","timestamp":1630457559110,"user_tz":-60,"elapsed":71,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}}},"source":["# set up training function \n","def train(model, iterator, optimizer, criterion):\n","\n","  model.train()\n","\n","  epoch_loss = 0\n","  epoch_acc = 0\n","\n","  #number of batches in iterator to calculate average\n","  n_batch = np.ceil(len(iterator.dataset) / batch_size) #in the case it is not divisible, round up  \n","\n","  for idx, (label, text) in enumerate(iterator):\n","    optimizer.zero_grad()\n","\n","    predictions = model(text)\n","\n","    loss = criterion(predictions, label)\n","    #softmax function here?\n","\n","    acc = categorical_accuracy(predictions, label)\n","\n","    loss.backward()\n","    optimizer.step()\n","\n","    epoch_loss += loss.item()\n","    epoch_acc += acc.item()\n","\n","  #return average loss and accuracy over all batches\n","  return epoch_loss / n_batch, epoch_acc / n_batch"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"HinrZq2OyIct","executionInfo":{"status":"ok","timestamp":1630457559111,"user_tz":-60,"elapsed":71,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}}},"source":["# set up evaluate function\n","\n","def evaluate(model, iterator, criterion):\n","\n","  model.eval()\n","\n","  epoch_loss = 0\n","  epoch_acc = 0\n","\n","  #number of batches in iterator to calculate average\n","  n_batch = np.ceil(len(iterator.dataset) / batch_size) #in the case it is not divisible, round u  \n","\n","\n","  with torch.no_grad():\n","\n","    for idx, (label, text) in enumerate(iterator):\n","\n","      predictions = model(text)     \n","\n","      loss = criterion(predictions, label)\n","      #softmax function here?\n","\n","      acc = categorical_accuracy(predictions, label)\n","\n","      epoch_loss += loss.item()\n","      epoch_acc += acc.item()\n","\n","      \n","  return epoch_loss / float(n_batch), epoch_acc / n_batch"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"sr_aOqvx2RzN","executionInfo":{"status":"ok","timestamp":1630457559112,"user_tz":-60,"elapsed":72,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}}},"source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"-2CQR3NOxmzN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630457559114,"user_tz":-60,"elapsed":73,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"bbac1fc2-7382-4773-98e9-9960390b6543"},"source":["## get number of trainable parameters\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","count_parameters(model)"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["29850"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"gxzOvQ_-2aSl"},"source":["# Train model"]},{"cell_type":"code","metadata":{"id":"QFDI4c1p2Uuf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630356242787,"user_tz":-60,"elapsed":2562440,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"1c55a59b-d548-4fcd-ac43-04db35630a2c"},"source":["n_epochs = 5\n","\n","for epoch in range(n_epochs):\n","\n","    save_path = f'/content/drive/My Drive/ARP/model/multiclass_freeze_{epoch}.pt'\n","\n","    start_time = time.time()\n","    \n","    train_loss, train_acc = train(model, train_bloader, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, val_bloader, criterion)\n","    \n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    torch.save(model.state_dict(), save_path)\n","    \n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 01 | Epoch Time: 9m 16s\n","\tTrain Loss: 1.850 | Train Acc: 35.60%\n","\t Val. Loss: 1.499 |  Val. Acc: 50.82%\n","Epoch: 02 | Epoch Time: 9m 14s\n","\tTrain Loss: 1.468 | Train Acc: 52.20%\n","\t Val. Loss: 1.310 |  Val. Acc: 57.38%\n","Epoch: 03 | Epoch Time: 9m 13s\n","\tTrain Loss: 1.337 | Train Acc: 57.48%\n","\t Val. Loss: 1.231 |  Val. Acc: 60.45%\n","Epoch: 04 | Epoch Time: 9m 13s\n","\tTrain Loss: 1.272 | Train Acc: 59.75%\n","\t Val. Loss: 1.192 |  Val. Acc: 61.86%\n","Epoch: 05 | Epoch Time: 9m 13s\n","\tTrain Loss: 1.234 | Train Acc: 61.01%\n","\t Val. Loss: 1.169 |  Val. Acc: 62.63%\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"66ZuEC0PJwLj","executionInfo":{"status":"ok","timestamp":1630359011504,"user_tz":-60,"elapsed":2768720,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"6d1b426c-703d-4e05-b86d-e639e6c4aef8"},"source":["#additional training\n","n_epochs = 10\n","\n","for epoch in range(5, n_epochs):\n","\n","    save_path = f'/content/drive/My Drive/ARP/model/multiclass_freeze_{epoch}.pt'\n","\n","    start_time = time.time()\n","    \n","    train_loss, train_acc = train(model, train_bloader, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, val_bloader, criterion)\n","    \n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    torch.save(model.state_dict(), save_path)\n","    \n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 06 | Epoch Time: 9m 13s\n","\tTrain Loss: 1.206 | Train Acc: 61.81%\n","\t Val. Loss: 1.144 |  Val. Acc: 63.19%\n","Epoch: 07 | Epoch Time: 9m 13s\n","\tTrain Loss: 1.184 | Train Acc: 62.58%\n","\t Val. Loss: 1.127 |  Val. Acc: 63.87%\n","Epoch: 08 | Epoch Time: 9m 13s\n","\tTrain Loss: 1.176 | Train Acc: 62.88%\n","\t Val. Loss: 1.128 |  Val. Acc: 63.78%\n","Epoch: 09 | Epoch Time: 9m 14s\n","\tTrain Loss: 1.164 | Train Acc: 63.17%\n","\t Val. Loss: 1.112 |  Val. Acc: 64.36%\n","Epoch: 10 | Epoch Time: 9m 13s\n","\tTrain Loss: 1.147 | Train Acc: 63.57%\n","\t Val. Loss: 1.113 |  Val. Acc: 64.35%\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pCx-i4dz-H8Y","executionInfo":{"status":"ok","timestamp":1630361852214,"user_tz":-60,"elapsed":2311101,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"82edbe5c-687a-4971-94fc-2d4c0ef2b778"},"source":["#even more trainig to verify model has converged\n","n_epochs = 15\n","\n","for epoch in range(10, n_epochs):\n","\n","    save_path = f'/content/drive/My Drive/ARP/model/multiclass_freeze_{epoch}.pt'\n","\n","    start_time = time.time()\n","    \n","    train_loss, train_acc = train(model, train_bloader, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, val_bloader, criterion)\n","    \n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    torch.save(model.state_dict(), save_path)\n","    \n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 11 | Epoch Time: 9m 14s\n","\tTrain Loss: 1.141 | Train Acc: 63.67%\n","\t Val. Loss: 1.115 |  Val. Acc: 64.19%\n","Epoch: 12 | Epoch Time: 9m 13s\n","\tTrain Loss: 1.130 | Train Acc: 64.06%\n","\t Val. Loss: 1.107 |  Val. Acc: 64.56%\n","Epoch: 13 | Epoch Time: 9m 15s\n","\tTrain Loss: 1.122 | Train Acc: 64.58%\n","\t Val. Loss: 1.107 |  Val. Acc: 64.63%\n","Epoch: 14 | Epoch Time: 9m 14s\n","\tTrain Loss: 1.112 | Train Acc: 64.89%\n","\t Val. Loss: 1.100 |  Val. Acc: 64.70%\n","Epoch: 15 | Epoch Time: 9m 14s\n","\tTrain Loss: 1.108 | Train Acc: 64.82%\n","\t Val. Loss: 1.083 |  Val. Acc: 65.40%\n"]}]},{"cell_type":"markdown","metadata":{"id":"XX5IAjoqu5zC"},"source":["# Evaluate model on test set"]},{"cell_type":"markdown","metadata":{"id":"HvpfDhiGb86c"},"source":["### Load model"]},{"cell_type":"code","metadata":{"id":"Tlwe0SC5u8_R","executionInfo":{"status":"ok","timestamp":1630457854394,"user_tz":-60,"elapsed":873,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}}},"source":["# load model with highest accuracy on validation set\n","\n","# best performing model was trained in epoch 3\n","\n","# path to model\n","model_path = '/content/drive/My Drive/ARP/model/multiclass_freeze_9.pt'\n","\n","if torch.cuda.is_available():\n","  model_dict = torch.load(model_path)\n","  model.load_state_dict(model_dict)\n","\n","else:\n","  model_dict = torch.load(model_path, map_location = torch.device('cpu'))\n","  model.load_state_dict(model_dict)"],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AHFmFNqvb_1L"},"source":["### Evaluate performance on test set\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"48fa_utvcRZl","executionInfo":{"status":"ok","timestamp":1630458056925,"user_tz":-60,"elapsed":198178,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"b0a641d8-15a0-4023-fec6-4bb329e78c86"},"source":["model.eval()\n","\n","test_loss, test_acc = evaluate(model, test_bloader, criterion)\n","\n","print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 1.109 | Test Acc: 64.55%\n"]}]},{"cell_type":"markdown","metadata":{"id":"kmgMTFB40gQS"},"source":["Construct function to classify new text instances\n"]},{"cell_type":"code","metadata":{"id":"RtuBYN6x0UHX"},"source":["def predict_class(model, sentence, min_len = 4):\n","\n","  model.eval()\n","\n","  classes = ['Society & Culture',\n","           'Science & Mathematics',\n","           'Health',\n","           'Education & Reference',\n","           'Computers & Internet',\n","           'Sports',\n","           'Business & Finance',\n","           'Entertainment & Music',\n","           'Family & Relationships',\n","           'Politics & Government']\n","\n","  class_labels = {num: text for num,text in enumerate(classes)}\n","\n","  #tokenise sentence\n","  tokenized  = [token.text for token in nlp.tokenizer(sentence)]\n","\n","  if len(tokenized) < min_len:\n","    tokenized += ['<pad>'] * (min_len - len(tokenized))\n","\n","  #convert sentences to vocabulary index\n","  indexed = [vocabulary.__getitem__(t) for t in tokenized]\n","\n","  #convert indices to tensors\n","  tensor = torch.LongTensor(indexed).to(device)\n","  tensor = tensor.unsqueeze(1)\n","\n","  #pass tensors to model to get predictions\n","  preds = model(tensor)\n","\n","  #get index of highest value in the tensor\n","  max_preds = preds.argmax(dim = 1)\n","  return class_labels[max_preds.item()]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SlCxBWTTgDIl"},"source":["def rank_class(model, sentence, min_len = 4, top_n = 3):\n","\n","  model.eval()\n","\n","  classes = ['Society & Culture',\n","           'Science & Mathematics',\n","           'Health',\n","           'Education & Reference',\n","           'Computers & Internet',\n","           'Sports',\n","           'Business & Finance',\n","           'Entertainment & Music',\n","           'Family & Relationships',\n","           'Politics & Government']\n","\n","  class_labels = {num: text for num,text in enumerate(classes)}\n","\n","  #tokenise sentence\n","  tokenized  = [token.text for token in nlp.tokenizer(sentence)]\n","\n","  if len(tokenized) < min_len:\n","    tokenized += ['<pad>'] * (min_len - len(tokenized))\n","\n","  #convert sentences to vocabulary index\n","  indexed = [vocabulary.__getitem__(t) for t in tokenized]\n","\n","  #convert indices to tensors\n","  tensor = torch.LongTensor(indexed).to(device)\n","  tensor = tensor.unsqueeze(1)\n","\n","  #pass tensors to model to get predictions\n","  preds = model(tensor)\n","\n","  print(preds)\n","  print(torch.sum(preds))\n","\n","  # get argsort of predictions to get ranking of predictions\n","  argsort_preds = torch.argsort(preds, descending = True)\n","\n","  #convert tensor to list\n","  argsort_list = argsort_preds.tolist()\n","  argsort_list = argsort_list[0]\n","\n","  #return the top n most probable categories\n","  top_preds = argsort_list[0:top_n]\n","\n","  #return the human-readable classes\n","  pred_classes = [class_labels[pred] for pred in top_preds]\n","\n","  return pred_classes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hIWWMCfDkZJC","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1629767260910,"user_tz":-60,"elapsed":178,"user":{"displayName":"YS Loh","photoUrl":"","userId":"02321814607652272974"}},"outputId":"1ac1ceda-709b-4d06-a9cf-a930b9c34cd2"},"source":["predict_class(model, \"What is the square root of one hundred?\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Science & Mathematics'"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjyVS6_SmR9b","executionInfo":{"status":"ok","timestamp":1630200816681,"user_tz":-60,"elapsed":182,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"93ce28da-7931-41fc-88d9-8d3ce62b4627"},"source":["rank_class(model, \"What is the square root of one hundred?\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[ 6.0399e-01,  2.1925e+00,  7.1033e-04,  1.4242e+00, -1.8090e+00,\n","         -4.0712e-02, -6.5696e-01, -3.1642e-01, -1.1956e+00, -8.8131e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward>)\n","tensor(-0.6786, device='cuda:0', grad_fn=<SumBackward0>)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['Science & Mathematics', 'Education & Reference', 'Society & Culture']"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jsQYjP4DiOI1","executionInfo":{"status":"ok","timestamp":1630200822147,"user_tz":-60,"elapsed":186,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"69b12a52-9b0a-4fc9-e27d-a9f5557b96f8"},"source":["rank_class(model, \"Where is Istanbul?\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[-0.2828,  0.0323,  0.3219, -0.0571, -0.4940,  0.1881,  0.2658,  0.2099,\n","         -0.1263, -0.8223]], device='cuda:0', grad_fn=<AddmmBackward>)\n","tensor(-0.7645, device='cuda:0', grad_fn=<SumBackward0>)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['Health', 'Business & Finance', 'Entertainment & Music']"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ShNT9OITifu1","executionInfo":{"status":"ok","timestamp":1630200937156,"user_tz":-60,"elapsed":183,"user":{"displayName":"LYS Machine Learning","photoUrl":"","userId":"04512863674460362512"}},"outputId":"5681d55e-00c8-46c4-d4af-6a8778ea6a05"},"source":["rank_class(model, \"What are the lyrics of the song Hysteria\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[ 0.8198, -1.7253, -2.1434, -0.8030, -0.5399, -0.0434, -0.2027,  4.4547,\n","         -0.4407, -2.6820]], device='cuda:0', grad_fn=<AddmmBackward>)\n","tensor(-3.3059, device='cuda:0', grad_fn=<SumBackward0>)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['Entertainment & Music', 'Society & Culture', 'Sports']"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"2lIFhAfKivV0"},"source":[""],"execution_count":null,"outputs":[]}]}